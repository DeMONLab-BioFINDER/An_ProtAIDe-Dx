{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import shutil\n",
    "import shap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bab33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set PYTHONPATH\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(ROOT_DIR) \n",
    "# import self-written modules\n",
    "from src.preproc.input_gen import gen_input_inference\n",
    "from src.ProtAIDeDx.main import args_parser as ProtAIDeDx_args_parser\n",
    "from src.ProtAIDeDx.main import main as ProtAIDeDx_main\n",
    "from src.utils.append_columns import append_columns\n",
    "from src.utils.print_ProtAIDeDx_results import print_ProtAIDeDx_results_CV\n",
    "from src.utils.metrics import clf_bas\n",
    "from src.ProtAIDeDx.misc.nn_helper import load_hyperParams, \\\n",
    "    load_pretrained_weights\n",
    "from src.ProtAIDeDx.misc.ProtAIDeDx_model import build_ProtAIDeDx\n",
    "from src.utils.io import txt2list, load_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment variables \n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "CKPT_DIR = os.path.join(ROOT_DIR, 'checkpoints')\n",
    "DATA_CV_CKPT_DIR = os.path.join(CKPT_DIR, 'data_proc', 'CV')\n",
    "MODEL_CKPT_DIR = os.path.join(CKPT_DIR, 'ProtAIDeDx')\n",
    "EXAMPLE_DATA_DIR = os.path.join(ROOT_DIR, 'example', 'data')\n",
    "EXAMPLE_RESULTS_DIR = os.path.join(ROOT_DIR, 'example', 'results')\n",
    "\n",
    "hyper_params_path=os.path.join(ROOT_DIR, \n",
    "                               'checkpoints', \n",
    "                               'ProtAIDeDx', 'ProtAIDeDx_HyperParams.csv') \n",
    "probaThresholds_path=os.path.join(ROOT_DIR, \n",
    "                                 'checkpoints', \n",
    "                                 'ProtAIDeDx', \n",
    "                                 'ProtAIDeDx_ProbaThresholds.csv') \n",
    "data_path = os.path.join(DATA_DIR, 'Simulated_SomaLogic_120Subjects.csv')\n",
    "targets = ['CU', 'AD', 'PD', 'FTD', 'ALS', 'StrokeTIA']\n",
    "biomarkers = ['Age_at_Visit','MMSE', 'CSF_pTau217', 'TauPET_MetaROI', \n",
    "              'MRI_CTADSign', 'MRI_WMH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating input for 10 folds of cross-validation\n",
    "for fold in range(10):\n",
    "    fold_ckpt_dir = os.path.join(DATA_CV_CKPT_DIR, f'fold_{fold}')\n",
    "    fold_deep_input_dir = os.path.join(\n",
    "        EXAMPLE_DATA_DIR, f'fold_{fold}', 'deep_input')\n",
    "    fold_splits_dir = os.path.join(\n",
    "        EXAMPLE_DATA_DIR, f'fold_{fold}', 'splits')\n",
    "    os.makedirs(fold_deep_input_dir, exist_ok=True)\n",
    "    os.makedirs(fold_splits_dir, exist_ok=True)\n",
    "\n",
    "    # generate input for inference\n",
    "    gen_input_inference(input_csv_path=data_path,\n",
    "                        output_dir=fold_deep_input_dir,\n",
    "                        ckpt_dir=fold_ckpt_dir,\n",
    "                        categ_vars=targets,\n",
    "                        conti_vars=[])\n",
    "    # copy data to 'fold_{fold}/splits' dir\n",
    "    shutil.copy2(data_path, os.path.join(fold_splits_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf77b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with pre-trained ProtAIDe-Dx models \n",
    "ProtAIDeDx_args = ProtAIDeDx_args_parser()\n",
    "ProtAIDeDx_args.suffix = 'CV'\n",
    "ProtAIDeDx_args.new = True \n",
    "\n",
    "# run inference for each fold\n",
    "for fold in range(10):\n",
    "    # set paths \n",
    "    fold_results_dir = os.path.join(\n",
    "        EXAMPLE_RESULTS_DIR, 'ProtAIDeDx', f'fold_{fold}')\n",
    "    os.makedirs(fold_results_dir, exist_ok=True)\n",
    "    fold_input_dir = os.path.join(\n",
    "        EXAMPLE_DATA_DIR, f'fold_{fold}', 'deep_input')\n",
    "    fold_splits_dir = os.path.join(\n",
    "        EXAMPLE_DATA_DIR, f'fold_{fold}', 'splits')\n",
    "    # set args\n",
    "    ProtAIDeDx_args.input_dir = fold_input_dir\n",
    "    ProtAIDeDx_args.checkpoint_dir = MODEL_CKPT_DIR\n",
    "    ProtAIDeDx_args.results_dir = fold_results_dir\n",
    "    ProtAIDeDx_args.splits_dir = fold_splits_dir\n",
    "    ProtAIDeDx_args.hyperParam_path = hyper_params_path\n",
    "    ProtAIDeDx_args.probaThresholds_path = probaThresholds_path\n",
    "    ProtAIDeDx_args.features_path = os.path.join(\n",
    "        DATA_CV_CKPT_DIR, f'fold_{fold}', 'input_aptamers.txt')\n",
    "    ProtAIDeDx_args.split  = 'fold_' + str(fold)\n",
    "    # run ProtAIDe-Dx inference\n",
    "    ProtAIDeDx_main(ProtAIDeDx_args)\n",
    "\n",
    "# postprocessing 'fold_{fold}/test_results.csv' \n",
    "# by appending true labels & biomarker columns \n",
    "cols2append = targets + biomarkers\n",
    "for fold in range(10):\n",
    "    fold_results_dir = os.path.join(\n",
    "        EXAMPLE_RESULTS_DIR, 'ProtAIDeDx', f'fold_{fold}')\n",
    "    fold_splits_dir = os.path.join(\n",
    "        EXAMPLE_DATA_DIR,  f'fold_{fold}', 'splits')\n",
    "    # load data \n",
    "    pred_df = pd.read_csv(os.path.join(fold_results_dir, 'test_results.csv'))\n",
    "    splits_df = pd.read_csv(os.path.join(fold_splits_dir, 'test.csv')) \n",
    "    merged_df = append_columns(pred_df,\n",
    "                               splits_df,\n",
    "                               cols_to_append=cols2append,\n",
    "                               keys=['PersonGroup_ID'])\n",
    "    # rename <target> columns as <target>-GT\n",
    "    for target in targets:\n",
    "        merged_df = merged_df.rename(columns={target: f'{target}-GT'})\n",
    "    \n",
    "    # reorder columns \n",
    "    target_full_cols  = []\n",
    "    for t in targets:\n",
    "        target_full_cols.append(f'{t}-GT')\n",
    "        target_full_cols.append(f'{t}-PredLabel')\n",
    "        target_full_cols.append(f'{t}-PredProb')\n",
    "    z_cols = [col for col in merged_df.columns if 'Z' in col]\n",
    "    ordered_cols = ['PersonGroup_ID', 'Visit', 'Contributor_Code'] \\\n",
    "        + target_full_cols + biomarkers + z_cols\n",
    "    merged_df = merged_df[ordered_cols]\n",
    "    # save data\n",
    "    merged_df.to_csv(\n",
    "        os.path.join(fold_results_dir, 'test_results_full.csv'), \n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb53108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out summarized results across 10 folds \n",
    "# !!! Note that the results are on **simult\n",
    "print_ProtAIDeDx_results_CV(\n",
    "    results_dir=os.path.join(EXAMPLE_RESULTS_DIR, 'ProtAIDeDx'),\n",
    "    sub_dirs_list=[f'fold_{fold}' for fold in range(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble predictions across 10 folds\n",
    "# i.e., if 5 out of 10 folds predict positive, \n",
    "# then the ensemble prediction is positive\n",
    "# this might be useful when you seek optimal performances on your own dataset\n",
    "\n",
    "def enumerate_predictions_CV(results_dir,\n",
    "                             threshold,\n",
    "                             nb_folds=10,\n",
    "                             sub_col='PersonGroup_ID',\n",
    "                             targets=targets):\n",
    "    \"\"\"\n",
    "    Ensemble predictions across CV folds.\n",
    "\n",
    "    Args:\n",
    "        results_dir (_type_): _description_\n",
    "        threshold (_type_): _description_\n",
    "        nb_folds (int, optional): _description_. Defaults to 10.\n",
    "        sub_col (str, optional): _description_. Defaults to 'PersonGroup_ID'.\n",
    "        targets (_type_, optional): _description_. Defaults to targets.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    targets_gt_cols = [f'{t}-GT' for t in targets]\n",
    "    fold0_pred_df = pd.read_csv(\n",
    "        os.path.join(results_dir, 'fold_0', 'test_results_full.csv'))\n",
    "    ensemble_pred_df = fold0_pred_df[\n",
    "        [sub_col] + targets_gt_cols].copy().set_index(sub_col)\n",
    "    \n",
    "    for t in targets:\n",
    "        ensemble_pred_df[f'{t}-PosCounts'] = 0\n",
    "    \n",
    "    for fold in range(nb_folds):\n",
    "        fold_results_dir = os.path.join(results_dir, f'fold_{fold}')\n",
    "        fold_pred_df = pd.read_csv(\n",
    "            os.path.join(\n",
    "                fold_results_dir, 'test_results.csv')).set_index(sub_col)\n",
    "        for t in targets:\n",
    "            ensemble_pred_df[f\"{t}-PosCounts\"] += fold_pred_df[\n",
    "                f\"{t}-PredLabel\"].astype(int)\n",
    "    for t in targets:\n",
    "        ensemble_pred_df[f'{t}-Ensemble'] = (\n",
    "            ensemble_pred_df[f'{t}-PosCounts'] >= threshold).astype(int)\n",
    "    cols2keep = [sub_col]\n",
    "    for t in targets:\n",
    "        cols2keep.append(f'{t}-GT')\n",
    "        cols2keep.append(f'{t}-PosCounts')\n",
    "        cols2keep.append(f'{t}-Ensemble')\n",
    "    \n",
    "    ensemble_pred_df = ensemble_pred_df.reset_index()[cols2keep]\n",
    "\n",
    "    return ensemble_pred_df\n",
    "\n",
    "# ensemble predictions across 10 folds with threshold = 5\n",
    "ensemble_pred_df = enumerate_predictions_CV(\n",
    "    results_dir=os.path.join(EXAMPLE_RESULTS_DIR, 'ProtAIDeDx'),\n",
    "    threshold=5,\n",
    "    nb_folds=10,\n",
    "    sub_col='PersonGroup_ID',\n",
    "    targets=targets)\n",
    "\n",
    "# get ensemble results\n",
    "BCA_ensembles = {}\n",
    "for t in targets:\n",
    "    BCA = clf_bas(\n",
    "        gt_vec=ensemble_pred_df[f'{t}-GT'].values.reshape(-1,),\n",
    "        pred_vec=ensemble_pred_df[f'{t}-Ensemble'].values.reshape(-1,))\n",
    "    BCA_ensembles[t] = BCA\n",
    "    print(f'Ensemble results for {t}: BCA={BCA:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of prediction performances\n",
    "# get performances per fold \n",
    "BCA_results = []\n",
    "for fold in range(10):\n",
    "    fold_results_dir = os.path.join(\n",
    "        EXAMPLE_RESULTS_DIR, 'ProtAIDeDx', f'fold_{fold}')\n",
    "    fold_metrics_df = pd.read_csv(\n",
    "        os.path.join(fold_results_dir, 'test_metrics.csv'))\n",
    "    fold_metrics_df['Hue'] = 'IndividualModel'\n",
    "    for t in targets:\n",
    "        BCA_results.append(\n",
    "            [t, \n",
    "             fold_metrics_df.loc[\n",
    "                 fold_metrics_df['target'] == t, 'BCA'].values[0], \n",
    "             'IndividualModel'])\n",
    "# results for ensemble \n",
    "for t in targets:\n",
    "    BCA_results.append([t, BCA_ensembles[t], 'EnsembleModel'])    \n",
    "\n",
    "BCA_results_df = pd.DataFrame(BCA_results, \n",
    "                              columns=['Target', 'BCA', 'Hue'])\n",
    "\n",
    "\n",
    "def plot_bca_box_plus_star(df):\n",
    "    targets = ['CU', 'AD', 'PD', 'FTD', 'ALS', 'StrokeTIA']\n",
    "    x = np.arange(len(targets))\n",
    "    jitter = 0.2  # separation between the two hues\n",
    "\n",
    "    ind = df[df[\"Hue\"] == \"IndividualModel\"]\n",
    "    ens = df[df[\"Hue\"] == \"EnsembleModel\"]\n",
    "\n",
    "    # colors\n",
    "    c_ind = \"C0\"\n",
    "    c_ens = \"C1\"\n",
    "\n",
    "    # boxplot (IndividualModel) shifted left\n",
    "    box_data = [ind.loc[\n",
    "        ind[\"Target\"] == t, \"BCA\"].dropna().to_numpy() for t in targets]\n",
    "    plt.boxplot(\n",
    "        box_data,\n",
    "        positions=x - jitter,\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=c_ind, alpha=0.35),\n",
    "        medianprops=dict(color=c_ind),\n",
    "        whiskerprops=dict(color=c_ind),\n",
    "        capprops=dict(color=c_ind),\n",
    "    )\n",
    "\n",
    "    # stars (EnsembleModel) shifted right\n",
    "    y_star = [ens.loc[ens[\"Target\"] == t, \"BCA\"].iloc[0] for t in targets]\n",
    "    plt.plot(\n",
    "        x + jitter, y_star,\n",
    "        linestyle=\"None\",\n",
    "        marker=\"*\",\n",
    "        markersize=13,\n",
    "        color=c_ens,\n",
    "    )\n",
    "\n",
    "    # legend\n",
    "    handles = [\n",
    "        Line2D([0], [0], marker=\"*\", linestyle=\"None\", \n",
    "               color=c_ens, markersize=13, label=\"EnsembleModel\"),\n",
    "        Patch(facecolor=c_ind, edgecolor=c_ind, alpha=0.35, \n",
    "              label=\"IndividualModel\"),\n",
    "    ]\n",
    "    plt.legend(handles=handles, loc=\"upper left\")\n",
    "\n",
    "    plt.xticks(x, targets)\n",
    "    plt.xlabel(\"Target\")\n",
    "    plt.ylabel(\"BCA\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_bca_box_plus_star(BCA_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e944ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of individual probability distributions based on fitted tSNE\n",
    "# TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHapley Additive exPlanations (SHAP) analysis\n",
    "# let's task model `fold_0`'s as an example. \n",
    "# let's use SHAP to explain PD predictions, background set is CU subjects\n",
    "\n",
    "# 1. define a model class based on pre-trained ProtAIDe-Dx models \n",
    "# load model \n",
    "ProtAIDeDx_args = ProtAIDeDx_args_parser()\n",
    "ProtAIDeDx_args.suffix = 'CV'\n",
    "ProtAIDeDx_args.split = 'fold_0'\n",
    "ProtAIDeDx_args.hyperParam_path = os.path.join(MODEL_CKPT_DIR,\n",
    "                                               'ProtAIDeDx_HyperParams.csv')\n",
    "ProtAIDeDx_args.features_path = os.path.join(DATA_CV_CKPT_DIR,\n",
    "                                             ProtAIDeDx_args.split,\n",
    "                                             'input_aptamers.txt')\n",
    "ProtAIDeDx_args.checkpoint_dir = MODEL_CKPT_DIR\n",
    "ProtAIDeDx_args.device = 'cpu'\n",
    "\n",
    "input_head_dim, encoder_dims, drop_out = load_hyperParams(\n",
    "    ProtAIDeDx_args.hyperParam_path,\n",
    "    ProtAIDeDx_args,\n",
    "    True\n",
    ")\n",
    "\n",
    "z_dim = int(encoder_dims[-1])\n",
    "input_aptamers = txt2list(ProtAIDeDx_args.features_path)\n",
    "InputHead, ProAIDeModel = build_ProtAIDeDx(len(input_aptamers),\n",
    "                                            input_head_dim,\n",
    "                                            encoder_dims,\n",
    "                                            drop_out)\n",
    "InputHead, ProAIDeModel = load_pretrained_weights(\n",
    "    InputHead,\n",
    "    ProAIDeModel,\n",
    "    ProtAIDeDx_args.checkpoint_dir,\n",
    "    ProtAIDeDx_args.suffix,\n",
    "    ProtAIDeDx_args.split,\n",
    "    ProtAIDeDx_args.device\n",
    ")\n",
    "\n",
    "class SHAPModel(nn.Module):\n",
    "    def __init__(self, InputHead, ProtAIDe, idx=2):\n",
    "        super(SHAPModel, self).__init__()\n",
    "        self.InputHead = InputHead\n",
    "        self.ProtAIDe = ProtAIDe\n",
    "        self.idx = idx\n",
    "        for param in self.InputHead.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.ProtAIDe.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred, _ = self.ProtAIDe(self.InputHead(x))\n",
    "        return pred[:, self.idx].reshape((-1, 1))\n",
    "\n",
    "PD_model = SHAPModel(InputHead, ProAIDeModel, idx=2)\n",
    "\n",
    "# 2. set background set \n",
    "# ! It's important to set a proper background set for SHAP analysis.\n",
    "# The role of the background set is to define the \"average\" model output.\n",
    "# Therefore, the background set should be representative.\n",
    "# For illustration purpose, we pick CU subjects as the background set.\n",
    "# In practice, you may want to use a larger & more representative set.\n",
    "# For example, we used whole training set as the background set in our paper.\n",
    "\n",
    "# load input data \n",
    "input_pkl = load_pkl(os.path.join(\n",
    "    EXAMPLE_DATA_DIR, 'fold_0', 'deep_input', 'test.pkl'))\n",
    "\n",
    "X_full = input_pkl['input']\n",
    "\n",
    "X_background = torch.tensor(input_pkl['input'][:20, :], \n",
    "                            dtype=torch.float32, \n",
    "                            device=ProtAIDeDx_args.device)\n",
    "X_explain    = torch.tensor(input_pkl['input'][40:60, :], \n",
    "                            dtype=torch.float32, \n",
    "                            device=ProtAIDeDx_args.device)\n",
    "# 3. SHAP DeepExplainer \n",
    "explainer = shap.DeepExplainer(\n",
    "    PD_model, \n",
    "    X_background)\n",
    "\n",
    "shap_values = explainer.shap_values(X_explain).reshape(\n",
    "    (X_explain.shape[0], -1))\n",
    "\n",
    "print(shap_values.shape)\n",
    "\n",
    "# 4. visualize SHAP values for 20 CU controls\n",
    "aptamer_info_df = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, 'Selected_SomaLogic7k_Aptamers.csv')\n",
    ")\n",
    "entez_symbols = []\n",
    "for aptamer in input_aptamers:\n",
    "    entrez_symbol = aptamer_info_df.loc[\n",
    "        aptamer_info_df['Feature'] == aptamer, 'EntrezGeneSymbol'].values[0]\n",
    "    entez_symbols.append(entrez_symbol)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    X_explain,\n",
    "    feature_names=entez_symbols,\n",
    "    show=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate biomarkers with predicted probabilities\n",
    "# let's take model `fold_0`'s outputs as an example \n",
    "# check correlation between ADPredProb with AD biomarkers \n",
    "fold_pred_df = pd.read_csv(\n",
    "    os.path.join(EXAMPLE_RESULTS_DIR, 'ProtAIDeDx', \n",
    "                 'fold_0', 'test_results_full.csv'))\n",
    "AD_prob_col = 'AD-PredProb'\n",
    "biomarkers_AD = ['MMSE', 'CSF_pTau217', 'TauPET_MetaROI', 'MRI_CTADSign']\n",
    "\n",
    "def plot_adprob_vs_biomarkers(\n",
    "    fold_pred_df,\n",
    "    AD_prob_col=\"AD-PredProb\",\n",
    "    AD_gt_col=\"AD-GT\",\n",
    "    biomarkers_AD=(\"MMSE\", \"CSF_pTau217\", \"TauPET_MetaROI\", \"MRI_CTADSign\"),\n",
    "    n_boot=500,\n",
    "    ci=95,\n",
    "):\n",
    "    fig, axes = plt.subplots(1, len(biomarkers_AD), \n",
    "                             figsize=(4.8 * len(biomarkers_AD), 4), \n",
    "                             sharex=True)\n",
    "    axes = np.ravel(axes)\n",
    "\n",
    "    x_all = pd.to_numeric(fold_pred_df[AD_prob_col], errors=\"coerce\")\n",
    "    gt_all = pd.to_numeric(fold_pred_df[AD_gt_col], errors=\"coerce\")\n",
    "\n",
    "    for ax, biom in zip(axes, biomarkers_AD):\n",
    "        y_all = pd.to_numeric(fold_pred_df[biom], errors=\"coerce\")\n",
    "        d = pd.DataFrame({\"x\": x_all, \"y\": y_all, \"gt\": gt_all}).dropna()\n",
    "\n",
    "        x = d[\"x\"].to_numpy()\n",
    "        y = d[\"y\"].to_numpy()\n",
    "        gt = d[\"gt\"].astype(int).to_numpy()\n",
    "\n",
    "        # color by AD-GT\n",
    "        colors = np.where(gt == 1, \"red\", \"blue\")\n",
    "        ax.scatter(x, y, s=15, c=colors)\n",
    "\n",
    "        if len(d) >= 3:\n",
    "            r, p = pearsonr(x, y)\n",
    "\n",
    "            # OLS fit\n",
    "            slope, intercept = np.polyfit(x, y, 1)\n",
    "            xg = np.linspace(x.min(), x.max(), 200)\n",
    "            yhat = intercept + slope * xg\n",
    "\n",
    "            # bootstrap CI for mean prediction\n",
    "            rng = np.random.default_rng(42)\n",
    "            y_boot = np.empty((n_boot, xg.size), dtype=float)\n",
    "            n = len(x)\n",
    "\n",
    "            for b in range(n_boot):\n",
    "                idx = rng.integers(0, n, size=n)\n",
    "                xb = x[idx]\n",
    "                yb = y[idx]\n",
    "                sb, ib = np.polyfit(xb, yb, 1)\n",
    "                y_boot[b] = ib + sb * xg\n",
    "\n",
    "            alpha = (100 - ci) / 2\n",
    "            lo = np.percentile(y_boot, alpha, axis=0)\n",
    "            hi = np.percentile(y_boot, 100 - alpha, axis=0)\n",
    "\n",
    "            ax.plot(xg, yhat)\n",
    "            ax.fill_between(xg, lo, hi, alpha=0.2)\n",
    "\n",
    "            ax.set_title(f\"{biom}\\nr={r:.2f}, p={p:.2g}\")\n",
    "        else:\n",
    "            ax.set_title(f\"{biom}\\n(r=NA, p=NA)\")\n",
    "\n",
    "        ax.set_xlabel(\"AD PredProb\")\n",
    "        ax.set_ylabel(biom)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_adprob_vs_biomarkers(fold_pred_df, AD_prob_col, \"AD-GT\", biomarkers_AD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abf410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate biomarkers with model embeddings\n",
    "# since the dimensionality last layer of model `fold_0` is 256\n",
    "# let's take model `fold_0`'s first 32 embeddings as an example\n",
    "z_cols = [f'Z{i}' for i in range(32)]\n",
    "\n",
    "def corr_heatmap_with_stars(df, z_cols, biomarker_cols, p_thr=0.05):\n",
    "    # r, p with rows=Biomarker (y), cols=Z (x)\n",
    "    r = pd.DataFrame(index=biomarker_cols, columns=z_cols, dtype=float)\n",
    "    p = pd.DataFrame(index=biomarker_cols, columns=z_cols, dtype=float)\n",
    "\n",
    "    for b in biomarker_cols:\n",
    "        y = pd.to_numeric(df[b], errors=\"coerce\")\n",
    "        for z in z_cols:\n",
    "            x = pd.to_numeric(df[z], errors=\"coerce\")\n",
    "            d = pd.DataFrame({\"x\": x, \"y\": y}).dropna()\n",
    "            if len(d) >= 3:\n",
    "                rr, pp = pearsonr(d[\"x\"].to_numpy(), d[\"y\"].to_numpy())\n",
    "                r.loc[b, z] = rr\n",
    "                p.loc[b, z] = pp\n",
    "            else:\n",
    "                r.loc[b, z] = np.nan\n",
    "                p.loc[b, z] = np.nan\n",
    "\n",
    "    ann = p.applymap(lambda v: \"*\" if pd.notna(v) and v < p_thr else \"\")\n",
    "\n",
    "    plt.figure(figsize=(0.6 * len(z_cols) + 2, 0.6 * len(biomarker_cols) + 2))\n",
    "    ax = sns.heatmap(\n",
    "        r,\n",
    "        cmap=\"coolwarm\",\n",
    "        vmin=-0.5, \n",
    "        vmax=0.5,\n",
    "        square=True,\n",
    "        annot=ann, \n",
    "        annot_kws={\"size\": 24},\n",
    "        fmt=\"\",\n",
    "        cbar_kws={\"label\": \"Pearson r\"},\n",
    "    )\n",
    "    ax.set_xlabel(\"Z\")\n",
    "    ax.set_ylabel(\"Biomarker\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "corr_heatmap_with_stars(\n",
    "    fold_pred_df,\n",
    "    z_cols=z_cols,\n",
    "    biomarker_cols=biomarkers,\n",
    "    p_thr=0.05,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProtAIDe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
